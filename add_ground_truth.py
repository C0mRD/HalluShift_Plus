#!/usr/bin/env python3
"""
Script to add ground truth annotations from COCO JSON files, LLAVA CSV file, or text QA datasets to the CSV generated by hallushift.py

This script matches images by filename and adds ground truth annotations as a new column.
Supports:
- COCO: caption annotations and instance annotations 
- LLAVA: generated descriptions
- TruthfulQA: best_answer and correct_answers
- TriviaQA: answer aliases
- TyDiQA: answer text and context
"""

import json
import pandas as pd
import argparse
import os
from pathlib import Path
from tqdm import tqdm
import sys
import glob
from datasets import load_dataset

def load_coco_annotations(json_file_path):
    """
    Load COCO annotations from JSON file and create mappings.
    
    Args:
        json_file_path (str): Path to COCO annotation JSON file
        
    Returns:
        tuple: (filename_to_annotations_dict, annotation_type)
    """
    print(f"Loading COCO annotations from: {json_file_path}")
    
    with open(json_file_path, 'r') as f:
        coco_data = json.load(f)
    
    # Create mapping from image_id to filename
    id_to_filename = {}
    for image_info in coco_data['images']:
        id_to_filename[image_info['id']] = image_info['file_name']
    
    # Create mapping from filename to annotations
    filename_to_annotations = {}
    
    # Determine annotation type
    if 'annotations' in coco_data and len(coco_data['annotations']) > 0:
        sample_annotation = coco_data['annotations'][0]
        
        if 'caption' in sample_annotation:
            annotation_type = 'captions'
            print("Detected caption annotations")
            
            # Group captions by image_id
            for annotation in coco_data['annotations']:
                image_id = annotation['image_id']
                caption = annotation['caption']
                
                if image_id in id_to_filename:
                    filename = id_to_filename[image_id]
                    
                    if filename not in filename_to_annotations:
                        filename_to_annotations[filename] = []
                    
                    filename_to_annotations[filename].append(caption)
        
        elif 'category_id' in sample_annotation:
            annotation_type = 'instances'
            print("Detected instance annotations")
            
            # Load categories for readable labels
            categories = {}
            if 'categories' in coco_data:
                for cat in coco_data['categories']:
                    categories[cat['id']] = cat['name']
            
            # Group instances by image_id
            for annotation in coco_data['annotations']:
                image_id = annotation['image_id']
                category_id = annotation['category_id']
                category_name = categories.get(category_id, f"category_{category_id}")
                
                if image_id in id_to_filename:
                    filename = id_to_filename[image_id]
                    
                    if filename not in filename_to_annotations:
                        filename_to_annotations[filename] = []
                    
                    # Create instance description
                    instance_info = {
                        'category': category_name,
                        'category_id': category_id,
                        'bbox': annotation.get('bbox', []),
                        'area': annotation.get('area', 0)
                    }
                    
                    filename_to_annotations[filename].append(instance_info)
        
        else:
            annotation_type = 'unknown'
            print("Warning: Unknown annotation type detected")
            
            # Generic handling - store the entire annotation
            for annotation in coco_data['annotations']:
                image_id = annotation['image_id']
                
                if image_id in id_to_filename:
                    filename = id_to_filename[image_id]
                    
                    if filename not in filename_to_annotations:
                        filename_to_annotations[filename] = []
                    
                    filename_to_annotations[filename].append(annotation)
    
    else:
        annotation_type = 'none'
        print("Warning: No annotations found in the JSON file")
    
    print(f"Loaded annotations for {len(filename_to_annotations)} images")
    return filename_to_annotations, annotation_type

def load_llava_ground_truth(llava_gt_csv_path):
    """
    Load LLAVA ground truth from CSV file containing generated_description.
    
    Args:
        llava_gt_csv_path (str): Path to LLAVA ground truth CSV file
        
    Returns:
        dict: filename_to_ground_truth mapping
    """
    print(f"Loading LLAVA ground truth from: {llava_gt_csv_path}")
    
    df = pd.read_csv(llava_gt_csv_path)
    
    # Check required columns
    if 'image_filename' not in df.columns:
        raise ValueError("LLAVA ground truth CSV must contain 'image_filename' column")
    if 'generated_description' not in df.columns:
        raise ValueError("LLAVA ground truth CSV must contain 'generated_description' column")
    
    # Create mapping from filename to ground truth
    filename_to_ground_truth = {}
    for _, row in df.iterrows():
        filename = row['image_filename']
        ground_truth = row['generated_description']
        filename_to_ground_truth[filename] = ground_truth
    
    print(f"Loaded ground truth for {len(filename_to_ground_truth)} images")
    return filename_to_ground_truth

def load_truthfulqa_ground_truth(max_samples=None):
    """
    Load TruthfulQA ground truth from HuggingFace dataset.
    
    Args:
        max_samples (int): Maximum number of samples to load (should match hallushift.py)
        
    Returns:
        dict: sample_name_to_ground_truth mapping
    """
    print("Loading TruthfulQA ground truth from HuggingFace dataset...")
    
    dataset = load_dataset("truthful_qa", 'generation')['validation']
    if max_samples:
        dataset = dataset.select(range(min(max_samples, len(dataset))))
    
    # Create mapping from sample name to ground truth
    sample_to_ground_truth = {}
    
    for idx, item in enumerate(dataset):
        sample_name = f"truthfulqa_sample_{idx}"
        
        # Extract ground truth information
        ground_truth_data = {
            'best_answer': item['best_answer'],
            'question': item['question']
        }
        
        sample_to_ground_truth[sample_name] = ground_truth_data
    
    print(f"Loaded ground truth for {len(sample_to_ground_truth)} TruthfulQA samples")
    return sample_to_ground_truth

def load_triviaqa_ground_truth(max_samples=None):
    """
    Load TriviaQA ground truth from HuggingFace dataset.
    
    Args:
        max_samples (int): Maximum number of samples to load (should match hallushift.py)
        
    Returns:
        dict: sample_name_to_ground_truth mapping
    """
    print("Loading TriviaQA ground truth from HuggingFace dataset...")
    
    dataset = load_dataset("trivia_qa", "rc.nocontext", split="validation")
    
    # Remove duplicates (same as in hallushift.py)
    id_mem = set()
    def remove_dups(batch):
        if batch['question_id'][0] in id_mem:
            return {_: [] for _ in batch.keys()}
        id_mem.add(batch['question_id'][0])
        return batch
    dataset = dataset.map(remove_dups, batch_size=1, batched=True, load_from_cache_file=False)
    
    if max_samples:
        dataset = dataset.select(range(min(max_samples, len(dataset))))
    
    # Create mapping from sample name to ground truth
    sample_to_ground_truth = {}
    
    for idx, item in enumerate(dataset):
        sample_name = f"triviaqa_sample_{idx}"
        
        # Extract ground truth information
        ground_truth_data = {
            'answer_aliases': item['answer']['aliases'],
            'answer_value': item['answer']['value'],
            'question': item['question']
        }
        
        sample_to_ground_truth[sample_name] = ground_truth_data
    
    print(f"Loaded ground truth for {len(sample_to_ground_truth)} TriviaQA samples")
    return sample_to_ground_truth

def load_tydiqa_ground_truth(max_samples=None):
    """
    Load TyDiQA ground truth from HuggingFace dataset.
    
    Args:
        max_samples (int): Maximum number of samples to load (should match hallushift.py)
        
    Returns:
        dict: sample_name_to_ground_truth mapping
    """
    print("Loading TyDiQA ground truth from HuggingFace dataset...")
    
    dataset = load_dataset("tydiqa", "secondary_task", split="train")
    
    # Filter for English questions (same as in hallushift.py)
    dataset = dataset.filter(lambda row: "english" in row["id"])
    
    if max_samples:
        dataset = dataset.select(range(min(max_samples, len(dataset))))
    
    # Create mapping from sample name to ground truth
    sample_to_ground_truth = {}
    
    for idx, item in enumerate(dataset):
        sample_name = f"tydiqa_sample_{idx}"
        
        # Extract ground truth information
        ground_truth_data = {
            'answers': item['answers'],
            'context': item['context'],
            'question': item['question']
        }
        
        sample_to_ground_truth[sample_name] = ground_truth_data
    
    print(f"Loaded ground truth for {len(sample_to_ground_truth)} TyDiQA samples")
    return sample_to_ground_truth

def format_ground_truth(annotations, annotation_type):
    """
    Format the ground truth annotations into a readable string.
    
    Args:
        annotations (list): List of annotations for an image
        annotation_type (str): Type of annotations (captions, instances, etc.)
        
    Returns:
        str or list: Formatted ground truth string or list of captions
    """
    if not annotations:
        return ""
    
    if annotation_type == 'captions':
        # Return the list of captions as-is for separate column handling
        return annotations
    
    elif annotation_type == 'instances':
        # Create a summary of detected objects
        categories = [ann['category'] for ann in annotations]
        category_counts = {}
        
        for cat in categories:
            category_counts[cat] = category_counts.get(cat, 0) + 1
        
        # Format as "category1(count1), category2(count2), ..."
        category_strings = []
        for cat, count in category_counts.items():
            if count > 1:
                category_strings.append(f"{cat}({count})")
            else:
                category_strings.append(cat)
        
        return ", ".join(category_strings)
    
    else:
        # Generic formatting - convert to string
        return str(annotations)

def add_mscoco_ground_truth_to_csv(csv_file_path, json_file_path, output_file_path=None, ground_truth_column_name='ground_truth'):
    """
    Add MSCOCO ground truth annotations to the CSV file.
    
    Args:
        csv_file_path (str): Path to input CSV file
        json_file_path (str): Path to COCO annotation JSON file
        output_file_path (str): Path to output CSV file (if None, overwrites input)
        ground_truth_column_name (str): Name of the new ground truth column (base name for multiple columns)
    """
    # Load the CSV file
    print(f"Loading CSV file: {csv_file_path}")
    df = pd.read_csv(csv_file_path)
    
    # Check if image_filename column exists
    if 'image_filename' not in df.columns:
        raise ValueError("CSV file must contain 'image_filename' column")
    
    print(f"Found {len(df)} rows in CSV file")
    
    # Load COCO annotations
    filename_to_annotations, annotation_type = load_coco_annotations(json_file_path)
    
    # Collect all ground truth data
    all_ground_truth_data = []
    matched_count = 0
    max_annotations = 0
    
    print("Matching images with ground truth annotations...")
    for idx, row in tqdm(df.iterrows(), total=len(df)):
        filename = row['image_filename']
        
        if filename in filename_to_annotations:
            annotations = filename_to_annotations[filename]
            ground_truth = format_ground_truth(annotations, annotation_type)
            matched_count += 1
            
            # For captions, ground_truth is a list; for others, it's a string
            if annotation_type == 'captions' and isinstance(ground_truth, list):
                all_ground_truth_data.append(ground_truth)
                max_annotations = max(max_annotations, len(ground_truth))
            else:
                # For non-caption annotations, treat as single item
                all_ground_truth_data.append([ground_truth] if ground_truth else [])
                max_annotations = max(max_annotations, 1 if ground_truth else 0)
        else:
            all_ground_truth_data.append([])  # No ground truth found
    
    print(f"Successfully matched {matched_count} out of {len(df)} images with ground truth")
    print(f"Match rate: {matched_count/len(df)*100:.1f}%")
    
    if annotation_type == 'captions':
        print(f"Maximum number of captions per image: {max_annotations}")
        
        # Create separate columns for each caption
        for i in range(max_annotations):
            column_name = f"{ground_truth_column_name}_{i+1}"
            column_values = []
            
            for ground_truth_list in all_ground_truth_data:
                if i < len(ground_truth_list):
                    column_values.append(ground_truth_list[i])
                else:
                    column_values.append("")  # Empty string for images with fewer captions
            
            df[column_name] = column_values
            print(f"Added column: {column_name}")
    
    else:
        # For non-caption annotations, add single column
        ground_truth_values = [gt_list[0] if gt_list else "" for gt_list in all_ground_truth_data]
        df[ground_truth_column_name] = ground_truth_values
        print(f"Added column: {ground_truth_column_name}")
    
    # Save the updated CSV
    if output_file_path is None:
        output_file_path = csv_file_path
    
    df.to_csv(output_file_path, index=False)
    print(f"Updated CSV saved to: {output_file_path}")
    
    return df

def add_llava_ground_truth_to_csv(csv_file_path, llava_gt_dict, output_file_path=None, ground_truth_column_name='ground_truth'):
    """
    Add LLAVA ground truth to the CSV file.
    
    Args:
        csv_file_path (str): Path to input CSV file
        llava_gt_dict (dict): Dictionary mapping filename to ground truth
        output_file_path (str): Path to output CSV file (if None, overwrites input)
        ground_truth_column_name (str): Name of the new ground truth column
    """
    # Load the CSV file
    print(f"Loading CSV file: {csv_file_path}")
    df = pd.read_csv(csv_file_path)
    
    # Check if image_filename column exists
    if 'image_filename' not in df.columns:
        raise ValueError("CSV file must contain 'image_filename' column")
    
    print(f"Found {len(df)} rows in CSV file")
    
    # Add ground truth column
    ground_truth_values = []
    matched_count = 0
    
    print("Matching images with LLAVA ground truth...")
    for _, row in tqdm(df.iterrows(), total=len(df)):
        filename = row['image_filename']
        
        if filename in llava_gt_dict:
            ground_truth_values.append(llava_gt_dict[filename])
            matched_count += 1
        else:
            ground_truth_values.append("")  # No ground truth found
    
    df[ground_truth_column_name] = ground_truth_values
    print(f"Added column: {ground_truth_column_name}")
    
    print(f"Successfully matched {matched_count} out of {len(df)} images with ground truth")
    print(f"Match rate: {matched_count/len(df)*100:.1f}%")
    
    # Save the updated CSV
    if output_file_path is None:
        output_file_path = csv_file_path
    
    df.to_csv(output_file_path, index=False)
    print(f"Updated CSV saved to: {output_file_path}")
    
    return df

def add_truthfulqa_ground_truth_to_csv(csv_file_path, truthfulqa_gt_dict, output_file_path=None, ground_truth_column_name='ground_truth'):
    """
    Add TruthfulQA ground truth to the CSV file.
    
    Args:
        csv_file_path (str): Path to input CSV file
        truthfulqa_gt_dict (dict): Dictionary mapping sample name to ground truth
        output_file_path (str): Path to output CSV file (if None, overwrites input)
        ground_truth_column_name (str): Name of the new ground truth column (base name)
    """
    # Load the CSV file
    print(f"Loading CSV file: {csv_file_path}")
    df = pd.read_csv(csv_file_path)
    
    print(f"Found {len(df)} rows in CSV file")
    
    # Add ground truth columns
    best_answers = []
    questions = []
    matched_count = 0
    
    print("Adding TruthfulQA ground truth...")
    for idx, row in tqdm(df.iterrows(), total=len(df)):
        sample_name = f"truthfulqa_sample_{idx}"
        
        if sample_name in truthfulqa_gt_dict:
            gt_data = truthfulqa_gt_dict[sample_name]
            best_answers.append(gt_data['best_answer'])
            questions.append(gt_data['question'])
            matched_count += 1
        else:
            best_answers.append("")
            questions.append("")
    
    # Add columns
    df[ground_truth_column_name] = best_answers
    df["question"] = questions
    
    print(f"Added columns: {ground_truth_column_name}, question")
    print(f"Successfully matched {matched_count} out of {len(df)} samples with ground truth")
    print(f"Match rate: {matched_count/len(df)*100:.1f}%")
    
    # Save the updated CSV
    if output_file_path is None:
        output_file_path = csv_file_path
    
    df.to_csv(output_file_path, index=False)
    print(f"Updated CSV saved to: {output_file_path}")
    
    return df

def add_triviaqa_ground_truth_to_csv(csv_file_path, triviaqa_gt_dict, output_file_path=None, ground_truth_column_name='ground_truth'):
    """
    Add TriviaQA ground truth to the CSV file.
    
    Args:
        csv_file_path (str): Path to input CSV file
        triviaqa_gt_dict (dict): Dictionary mapping sample name to ground truth
        output_file_path (str): Path to output CSV file (if None, overwrites input)
        ground_truth_column_name (str): Name of the new ground truth column (base name)
    """
    # Load the CSV file
    print(f"Loading CSV file: {csv_file_path}")
    df = pd.read_csv(csv_file_path)
    
    print(f"Found {len(df)} rows in CSV file")
    
    # Add ground truth columns
    answer_aliases_list = []
    answer_values = []
    questions = []
    matched_count = 0
    
    print("Adding TriviaQA ground truth...")
    for idx, row in tqdm(df.iterrows(), total=len(df)):
        sample_name = f"triviaqa_sample_{idx}"
        
        if sample_name in triviaqa_gt_dict:
            gt_data = triviaqa_gt_dict[sample_name]
            answer_aliases_list.append("; ".join(gt_data['answer_aliases']))
            answer_values.append(gt_data['answer_value'])
            questions.append(gt_data['question'])
            matched_count += 1
        else:
            answer_aliases_list.append("")
            answer_values.append("")
            questions.append("")
    
    # Add columns
    df[f"{ground_truth_column_name}_aliases"] = answer_aliases_list
    df[f"{ground_truth_column_name}_value"] = answer_values
    df["question"] = questions
    
    print(f"Added columns: {ground_truth_column_name}_aliases, {ground_truth_column_name}_value, question")
    print(f"Successfully matched {matched_count} out of {len(df)} samples with ground truth")
    print(f"Match rate: {matched_count/len(df)*100:.1f}%")
    
    # Save the updated CSV
    if output_file_path is None:
        output_file_path = csv_file_path
    
    df.to_csv(output_file_path, index=False)
    print(f"Updated CSV saved to: {output_file_path}")
    
    return df

def add_tydiqa_ground_truth_to_csv(csv_file_path, tydiqa_gt_dict, output_file_path=None, ground_truth_column_name='ground_truth'):
    """
    Add TyDiQA ground truth to the CSV file.
    
    Args:
        csv_file_path (str): Path to input CSV file
        tydiqa_gt_dict (dict): Dictionary mapping sample name to ground truth
        output_file_path (str): Path to output CSV file (if None, overwrites input)
        ground_truth_column_name (str): Name of the new ground truth column (base name)
    """
    # Load the CSV file
    print(f"Loading CSV file: {csv_file_path}")
    df = pd.read_csv(csv_file_path)
    
    print(f"Found {len(df)} rows in CSV file")
    
    # Add ground truth columns
    answers_list = []
    contexts = []
    questions = []
    matched_count = 0
    
    print("Adding TyDiQA ground truth...")
    for idx, row in tqdm(df.iterrows(), total=len(df)):
        sample_name = f"tydiqa_sample_{idx}"
        
        if sample_name in tydiqa_gt_dict:
            gt_data = tydiqa_gt_dict[sample_name]
            # Convert answers to string representation if it's a complex object
            answers = gt_data['answers']
            if isinstance(answers, dict):
                answers_list.append(str(answers))
            elif isinstance(answers, list):
                answers_list.append("; ".join(map(str, answers)))
            else:
                answers_list.append(str(answers))
            contexts.append(gt_data['context'])
            questions.append(gt_data['question'])
            matched_count += 1
        else:
            answers_list.append("")
            contexts.append("")
            questions.append("")
    
    # Add columns
    df[ground_truth_column_name] = answers_list
    df["context"] = contexts
    df["question"] = questions
    
    print(f"Added columns: {ground_truth_column_name}, context, question")
    print(f"Successfully matched {matched_count} out of {len(df)} samples with ground truth")
    print(f"Match rate: {matched_count/len(df)*100:.1f}%")
    
    # Save the updated CSV
    if output_file_path is None:
        output_file_path = csv_file_path
    
    df.to_csv(output_file_path, index=False)
    print(f"Updated CSV saved to: {output_file_path}")
    
    return df

def process_folder(input_folder, output_folder, dataset_type, json_file=None, llava_gt_csv=None, ground_truth_column_name='ground_truth', max_samples=None):
    """
    Process all CSV files in the input folder and add ground truth annotations.
    
    Args:
        input_folder (str): Path to input folder containing CSV files
        output_folder (str): Path to output folder for processed CSV files
        dataset_type (str): 'mscoco', 'llava', 'truthfulqa', or 'triviaqa'
        json_file (str): Path to COCO annotation JSON file (for mscoco)
        llava_gt_csv (str): Path to LLAVA ground truth CSV file (for llava)
        ground_truth_column_name (str): Name of the ground truth column
        max_samples (int): Maximum number of samples to load (for text datasets)
    """
    # Create output folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)
    
    # Find all CSV files in input folder
    csv_files = glob.glob(os.path.join(input_folder, "*.csv"))
    
    if not csv_files:
        print(f"No CSV files found in {input_folder}")
        return
    
    print(f"Found {len(csv_files)} CSV files to process")
    
    if dataset_type == 'llava':
        # Load LLAVA ground truth once
        llava_gt_dict = load_llava_ground_truth(llava_gt_csv)
    elif dataset_type == 'truthfulqa':
        # Load TruthfulQA ground truth once
        truthfulqa_gt_dict = load_truthfulqa_ground_truth(max_samples)
    elif dataset_type == 'triviaqa':
        # Load TriviaQA ground truth once
        triviaqa_gt_dict = load_triviaqa_ground_truth(max_samples)
    elif dataset_type == 'tydiqa':
        # Load TyDiQA ground truth once
        tydiqa_gt_dict = load_tydiqa_ground_truth(max_samples)
    
    # Process each CSV file
    for csv_file in csv_files:
        print(f"\n{'='*50}")
        print(f"Processing: {os.path.basename(csv_file)}")
        print(f"{'='*50}")
        
        # Generate output file path
        csv_filename = Path(csv_file).name
        output_file = os.path.join(output_folder, csv_filename.replace('.csv', '_with_gt.csv'))
        
        try:
            if dataset_type == 'mscoco':
                add_mscoco_ground_truth_to_csv(
                    csv_file_path=csv_file,
                    json_file_path=json_file,
                    output_file_path=output_file,
                    ground_truth_column_name=ground_truth_column_name
                )
            elif dataset_type == 'llava':
                add_llava_ground_truth_to_csv(
                    csv_file_path=csv_file,
                    llava_gt_dict=llava_gt_dict,
                    output_file_path=output_file,
                    ground_truth_column_name=ground_truth_column_name
                )
            elif dataset_type == 'truthfulqa':
                add_truthfulqa_ground_truth_to_csv(
                    csv_file_path=csv_file,
                    truthfulqa_gt_dict=truthfulqa_gt_dict,
                    output_file_path=output_file,
                    ground_truth_column_name=ground_truth_column_name
                )
            elif dataset_type == 'triviaqa':
                add_triviaqa_ground_truth_to_csv(
                    csv_file_path=csv_file,
                    triviaqa_gt_dict=triviaqa_gt_dict,
                    output_file_path=output_file,
                    ground_truth_column_name=ground_truth_column_name
                )
            elif dataset_type == 'tydiqa':
                add_tydiqa_ground_truth_to_csv(
                    csv_file_path=csv_file,
                    tydiqa_gt_dict=tydiqa_gt_dict,
                    output_file_path=output_file,
                    ground_truth_column_name=ground_truth_column_name
                )
            
            print(f"Successfully processed: {csv_filename}")
            
        except Exception as e:
            print(f"Error processing {csv_filename}: {str(e)}")
            continue

def main():
    parser = argparse.ArgumentParser(description="Add ground truth annotations from COCO JSON, LLAVA CSV, or text QA datasets to CSV files")
    parser.add_argument('--dataset', type=str, choices=['mscoco', 'llava', 'truthfulqa', 'triviaqa', 'tydiqa'], required=True, 
                       help='Dataset type: mscoco, llava, truthfulqa, triviaqa, or tydiqa')
    parser.add_argument('--input_folder', type=str, required=True, 
                       help='Path to input folder containing CSV files')
    parser.add_argument('--output_folder', type=str, required=True, 
                       help='Path to output folder for processed CSV files')
    parser.add_argument('--json_file', type=str, default=None, 
                       help='Path to COCO annotation JSON file (required for mscoco)')
    parser.add_argument('--llava_gt_csv', type=str, default=None, 
                       help='Path to LLAVA ground truth CSV file (required for llava)')
    parser.add_argument('--max_samples', type=int, default=None, 
                       help='Maximum number of samples to load (for text datasets, should match hallushift.py)')
    parser.add_argument('--column_name', type=str, default='ground_truth', 
                       help='Name of the new ground truth column')
    
    args = parser.parse_args()
    
    # Validate dataset-specific arguments
    if args.dataset == 'mscoco':
        if not args.json_file:
            print("Error: --json_file is required for mscoco dataset")
            sys.exit(1)
        if not os.path.exists(args.json_file):
            print(f"Error: JSON file not found: {args.json_file}")
            sys.exit(1)
    
    elif args.dataset == 'llava':
        if not args.llava_gt_csv:
            print("Error: --llava_gt_csv is required for llava dataset")
            sys.exit(1)
        if not os.path.exists(args.llava_gt_csv):
            print(f"Error: LLAVA ground truth CSV file not found: {args.llava_gt_csv}")
            sys.exit(1)
    
    elif args.dataset in ['truthfulqa', 'triviaqa', 'tydiqa']:
        # Text datasets will be loaded from HuggingFace - no additional files needed
        pass
    
    # Validate input folder
    if not os.path.exists(args.input_folder):
        print(f"Error: Input folder not found: {args.input_folder}")
        sys.exit(1)
    
    print(f"""
    =========================================================================
                    Adding Ground Truth Annotations to CSV Files
    =========================================================================
    Dataset Type: {args.dataset.upper()}
    Input Folder: {args.input_folder}
    Output Folder: {args.output_folder}
    {"JSON File: " + args.json_file if args.json_file else ""}
    {"LLAVA GT CSV: " + args.llava_gt_csv if args.llava_gt_csv else ""}
    {"Max Samples: " + str(args.max_samples) if args.max_samples else "Max Samples: All"}
    Ground Truth Column: {args.column_name}
    =========================================================================
    """)
    
    try:
        process_folder(
            input_folder=args.input_folder,
            output_folder=args.output_folder,
            dataset_type=args.dataset,
            json_file=args.json_file,
            llava_gt_csv=args.llava_gt_csv,
            ground_truth_column_name=args.column_name,
            max_samples=args.max_samples
        )
        
        print(f"\nSuccess! All CSV files processed and saved to {args.output_folder}")
        print("=========================================================================")
        
    except Exception as e:
        print(f"Error: {str(e)}")
        sys.exit(1)

if __name__ == '__main__':
    main() 